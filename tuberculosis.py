# -*- coding: utf-8 -*-
"""tuberculosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t5x_bWG7Q1qCJrSUM4UCKygT3ec-JxaZ
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
from tensorflow import keras
import os

# Plotting libraries
import plotly.figure_factory as ff
import matplotlib.pyplot as plt

from tqdm import tqdm

from google.colab import files
files.upload()
import pandas as pd
df = pd.read_csv('shenzhen_metadata.csv')  # Load into pandas
df.head()

df['findings_lower'] = df['findings'].str.lower()

# Calculate total number of TB cases
total_tb = df['findings_lower'].str.contains('tb', na=False).sum()
print(f"Total number of TB cases: {total_tb}")
normal_count = len(df[df['findings'] == 'normal'])
print(f"Number of normal cases: {normal_count}")

# Calculate the number of females in the dataframe.
female_count = len(df[df['sex'] == 'Female'])

# Display the result.
print(f"Number of females: {female_count}")
male_count = len(df[df['sex'] == 'Male'])
print(f"Number of males: {male_count}")

age_min = df['age'].min()
age_max = df['age'].max()
age_range = age_max - age_min


print(f"Minimum Age: {age_min}")
print(f"Maximum Age: {age_max}")
print(f"Age Range: {age_range}")

df.reset_index(inplace=True)
print("Variables:")
print(df.columns)

print("\nNull entries check:")
print(df.isnull().sum())

for col_ in df.columns[2:]:
    print("Variable:", col_)
    # Get unique entries for string variables
    if isinstance(df[col_][0], str):
        unique_entries, counts = np.unique(df[col_], return_counts=True)
        for entry_, count_ in zip(unique_entries, counts):
            print(entry_, ": ", count_)
    else:
        # Print summary statistics for numeric variables
        print(df[col_].describe())
    print("\n")

male_ages = df["age"].loc[df["sex"]=="Male"]
female_ages = df["age"].loc[df["sex"]=="Female"]
fig = ff.create_distplot(
    [male_ages, female_ages], ["male", "female"],
    bin_size=3, show_curve=False, histnorm=None
)
fig.update_layout(title="Distribution of gender-based age groups")
fig.show()

df["labels"] = df["findings"].copy()

for i, label_ in enumerate(df["labels"], start=0):
    label_ = label_.lower()

    if "ptb" in label_ or "tb" in label_ or "stb" in label_:
        df["labels"][i] = "tuberculosis"
    elif "normal" in label_:
        continue
    else:
        df["labels"][i] = None
print("Labels:", df["labels"].value_counts())
print("Dropped:", df["labels"].isnull().sum())

df =df.dropna()

from google.colab import files
files.upload()

image_dir = "/content/drive/MyDrive/project/images"
n_samples = 3

labels_list =df["labels"].value_counts().keys().to_list()

img_samples = {label_: list() for label_ in labels_list}
for label_ in img_samples.keys():
    img_samples_ = df.loc[df["labels"] == label_]["study_id"].sample(n_samples)
    img_samples[label_] = img_samples_

# Get all image arrays
img_arrs = {name_: None for name_ in df["study_id"]}
for name_ in tqdm(img_arrs.keys()):
    image = keras.preprocessing.image.load_img(
        os.path.join(image_dir, name_),
        target_size=(224, 224), color_mode="grayscale"
    )
    image_arr = keras.preprocessing.image.img_to_array(image, data_format="channels_last", dtype=None)
    img_arrs[name_] = image_arr

fig, axes = plt.subplots(nrows=len(labels_list), ncols=n_samples, figsize=(20, 20))

for row_, label_ in enumerate(img_samples.keys()):
    for col_, name_ in enumerate(img_samples[label_]):
        axes[row_, col_].imshow(img_arrs[name_], cmap="gray")
        axes[row_, 0].set(ylabel=label_)

"""A grid is created with rows corresponding to each label and columns corresponding to the number of image samples (n_samples).
For each row, the images associated with the current label (label_) are displayed in grayscale.
The y-axis of the first column in each row is labeled with the respective label (label_) to describe what category of images is being shown.
"""

from skimage.exposure import equalize_adapthist
from skimage.filters import threshold_isodata, gaussian

print('Preprocessing images...')
img_arrs_preprocessed = {name_: None for name_ in img_arrs.keys()}
for name_, arr_ in tqdm(img_arrs.items()):
    # Image normalization to [0, 1]
    arr_ /= arr_.max()

    # Histogram equalization
    arr_clahe = equalize_adapthist(arr_, kernel_size=15, clip_limit=0.05)

    # Gaussian smoothing
    arr_gaussian = gaussian(arr_clahe, sigma=0.5)
    img_arrs_preprocessed[name_] = arr_gaussian

"""Normalizing the pixel values to the range [0, 1].
Enhancing the contrast using adaptive histogram equalization (CLAHE).
Applying Gaussian smoothing to reduce noise.
"""

fig, axes = plt.subplots(nrows=len(labels_list), ncols=n_samples, figsize=(20, 20))

for row_, label_ in enumerate(img_samples.keys()):
    for col_, name_ in enumerate(img_samples[label_]):
        axes[row_, col_].imshow(img_arrs_preprocessed[name_], cmap="gray")
        axes[row_, 0].set(ylabel=label_)

data = [arr_ for arr_ in img_arrs_preprocessed.values()]
data = np.array(data)

from sklearn.model_selection import train_test_split

binary_labels = np.where(df["findings"]=="normal", 0, 1)
X_train, X_test, y_train, y_test = train_test_split(df, binary_labels, test_size=0.2,
                                                random_state=42)

from tensorflow.keras import models, layers
conv_kernel = 5

model = models.Sequential()
model.add(layers.Conv2D(32, (conv_kernel, conv_kernel), activation='relu', input_shape=(224, 224, 1)))
model.add(layers.MaxPooling2D((3, 3)))
model.add(layers.Conv2D(64, (conv_kernel, conv_kernel), activation='relu'))
model.add(layers.MaxPooling2D((3, 3)))
model.add(layers.Conv2D(128, (conv_kernel, conv_kernel), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dropout(0.25))
model.add(layers.Dense(1, activation='sigmoid'))

model.summary()

model.compile(
    loss='binary_crossentropy',
    optimizer=keras.optimizers.Adam(learning_rate=5e-4),
    metrics=['accuracy']  # Wrap 'accuracy' in a list
)

history = model.fit(
    X_train,
    y_train,
    batch_size=128,
    epochs=30,
    verbose=1,
    validation_split = 0.1,
    shuffle=True
)

fig, ax = plt.subplots(1, 2, figsize=(10,6))
ax[0].plot(np.sqrt(history.history['loss']), 'r', label='train')
ax[0].plot(np.sqrt(history.history['val_loss']), 'b' ,label='val')
ax[0].set_xlabel('Epoch')
ax[0].set_ylabel('Loss')
ax[0].legend()

# Accuracy
ax[1].plot(np.sqrt(history.history['accuracy']), 'r', label='train')
ax[1].plot(np.sqrt(history.history['val_accuracy']), 'b' ,label='val')
ax[1].set_xlabel('Epoch')
ax[1].set_ylabel('Accuracy')
ax[1].legend()

fig.show()

results = model.evaluate(X_test, y_test, batch_size=64)
print("Test loss, Test acc:", results)

"""model creation"""

pip install tensorflow pandas numpy matplotlib pillow scikit-learn

import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Add
from sklearn.model_selection import train_test_split
import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt
import pandas as pd

# Assuming your dataset has two columns: "image_path" and "caption"
data = pd.read_csv('/content/shenzhen_metadata.csv')

# Parameters
BATCH_SIZE = 64
BUFFER_SIZE = 1000
MAX_LEN = 30  # Maximum caption length
VOCAB_SIZE = 5000  # Max vocabulary size
EMBEDDING_DIM = 256
UNITS = 512
IMG_SIZE = (299, 299)  # For InceptionV3

# Preprocess images
def load_image(image_path):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, IMG_SIZE)
    img = tf.keras.applications.inception_v3.preprocess_input(img)
    return img, image_path

# Tokenize captions
tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<UNK>', filters='!"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')
tokenizer.fit_on_texts(data["findings"].values)
cap_seqs = tokenizer.texts_to_sequences(data["findings"].values)
cap_seqs = pad_sequences(cap_seqs, maxlen=MAX_LEN, padding='post')

# Split dataset into training and validation
train_captions, val_captions, train_images, val_images = train_test_split(cap_seqs, data['study_id'], test_size=0.2)

# Create TensorFlow dataset
def map_func(img_name, cap):
    img_tensor, img_name = load_image(img_name)
    return img_tensor, cap

dataset = tf.data.Dataset.from_tensor_slices((train_images, train_captions))
dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)
dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_captions))
val_dataset = val_dataset.map(map_func).batch(BATCH_SIZE)

# Use InceptionV3 as a feature extractor
image_model = InceptionV3(include_top=False, weights='imagenet')
new_input = image_model.input
hidden_layer = image_model.layers[-1].output  # Use output before the classification layer

image_features_extract_model = tf.keras.Model(new_input, hidden_layer)

# Extract features
def extract_image_features(img_tensor):
    features = image_features_extract_model(img_tensor)
    features = tf.reshape(features, (features.shape[0], -1, features.shape[3]))
    return features

class BahdanauAttention(tf.keras.layers.Layer):
    def __init__(self, units):
        super(BahdanauAttention, self).__init__()
        self.W1 = tf.keras.layers.Dense(units)
        self.W2 = tf.keras.layers.Dense(units)
        self.V = tf.keras.layers.Dense(1)

    def call(self, features, hidden):
        hidden_with_time_axis = tf.expand_dims(hidden, 1)
        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))
        attention_weights = tf.nn.softmax(self.V(score), axis=1)
        context_vector = attention_weights * features
        context_vector = tf.reduce_sum(context_vector, axis=1)
        return context_vector, attention_weights

class ImageCaptioningModel(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, units):
        super(ImageCaptioningModel, self).__init__()
        self.units = units
        self.attention = BahdanauAttention(self.units)
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.lstm = tf.keras.layers.LSTM(self.units, return_sequences=True, return_state=True)
        self.fc1 = tf.keras.layers.Dense(self.units)
        self.fc2 = tf.keras.layers.Dense(vocab_size)

    def call(self, img_features, captions):
        # Attention mechanism
        hidden = tf.zeros((img_features.shape[0], self.units))
        context_vector, attention_weights = self.attention(img_features, hidden)

        # LSTM for text generation
        embedded_captions = self.embedding(captions)
        lstm_input = tf.concat([tf.expand_dims(context_vector, 1), embedded_captions], axis=-1)
        lstm_output, _, _ = self.lstm(lstm_input)
        x = self.fc1(lstm_output)
        x = tf.nn.relu(x)
        x = self.fc2(x)

        return x, attention_weights

optimizer = tf.keras.optimizers.Adam()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')

def loss_function(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)
    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask
    return tf.reduce_mean(loss_)

@tf.function
def train_step(img_tensor, target):
    loss = 0
    with tf.GradientTape() as tape:
        img_features = extract_image_features(img_tensor)
        predictions, _ = model(img_features, target)
        loss = loss_function(target, predictions)

    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss

EPOCHS = 20

for epoch in range(EPOCHS):
    total_loss = 0
    for batch, (img_tensor, target) in enumerate(dataset):
        batch_loss = train_step(img_tensor, target)
        total_loss += batch_loss

    print(f"Epoch {epoch+1} Loss {total_loss/len(dataset):.4f}")